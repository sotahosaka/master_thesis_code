{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f6ed89-baad-4e56-8bbf-6e1d82a1d5c2",
   "metadata": {},
   "source": [
    "# Making MobileNet as Base model\n",
    "## learning MobileNet v1 using wire raw images and evaliuating the precision using drift images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a459bd-9528-4fc8-89c9-1fad13d94611",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d0f3a-68e9-41b5-a5ca-8f8c23c0f8c6",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14abab-e009-41bb-8859-5ef250e24f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de51691-164d-4689-89bc-40558acf797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuction for making label\n",
    "def create_image_labels(n_light, n_water, n_blackline, n_discoloration, n_dotsonline, n_adhesion, n_scratch):\n",
    "    \"\"\"\n",
    "    function for making label corresponding to each abnormal mode\n",
    "    \n",
    "    Args:\n",
    "        n_light (int): the number of light images\n",
    "        n_water (int): the number of water images\n",
    "        n_blackline (int): the number of black line images\n",
    "        n_discoloration (int): the number of discoloration images\n",
    "        n_dotsonline (int): the number of dots on line images\n",
    "        n_adhesion (int): the number of adhesion images\n",
    "        n_scrtch (int): the number of surface scratches images\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: 1collumn=image„ÄÅ2collumn=label\n",
    "    \"\"\"\n",
    "    # Name list for each abnormal mode\n",
    "    light_data = [f\"Light-{i}\" for i in range(1, n_light + 1)]\n",
    "    water_data = [f\"Water-{i}\" for i in range(1, n_water + 1)]\n",
    "    blackline_data = [f\"BlackLine-{i}\" for i in range(1, n_blackline + 1)]\n",
    "    discoloration_data = [f\"Discoloration-{i}\" for i in range(1, n_discoloration + 1)]\n",
    "    dotsonline_data = [f\"DotsOnLine-{i}\" for i in range(1, n_dotsonline + 1)]\n",
    "    copper_data = [f\"Adhesion-{i}\" for i in range(1, n_adhesion + 1)]\n",
    "    spark_data = [f\"SurfaceScratch-{i}\" for i in range(1, n_scratch + 1)]\n",
    "\n",
    "    # Label list\n",
    "    light_labels = [0] * n_light\n",
    "    water_labels = [1] * n_water\n",
    "    blackline_labels = [2] * n_blackline\n",
    "    discoloration_labels = [3] * n_discoloration\n",
    "    dotsonline_labels = [4] * n_dotsonline\n",
    "    adhesion_labels = [5] * n_adhesion\n",
    "    scratch_labels = [6] * n_scratch\n",
    "\n",
    "    # make dataframe by combining data\n",
    "    data = list(zip(light_data + water_data + blackline_data + discoloration_data + dotsonline_data + copper_data + spark_data, \n",
    "                    light_labels + water_labels + blackline_labels + discoloration_labels + dotsonline_labels + copper_labels + spark_labels))\n",
    "    df = pd.DataFrame(data, columns=[\"image\", \"label\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_7mode_images(src_dirs):\n",
    "    \"\"\"\n",
    "    src_dirs: list containing full pass of seven folders\n",
    "              ex: [\n",
    "                   r\"C:/path/mode0/*jpg\",\n",
    "                   r\"C:/path/mode1/*jpg\",\n",
    "                   ...\n",
    "                  ]\n",
    "\n",
    "    return:\n",
    "      all_images      :list of all images(cv2) \n",
    "      images_by_class : list of each abnormal mode images [list0, list1, ..., list6]\n",
    "      labels          : list of labels corresponding to each image\n",
    "      nums            : list of the number of each class images [n0,n1,...,n6]\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(src_dirs) == 7, \"Designate 7 folder pass\"\n",
    "\n",
    "    images_by_class = []\n",
    "    nums = []\n",
    "\n",
    "    # process\n",
    "    for i, path in enumerate(src_dirs):\n",
    "        filepaths = glob.glob(path)\n",
    "        print(f\"Class {i}: {len(filepaths)} files\")\n",
    "\n",
    "        imgs = []\n",
    "        for fp in filepaths:\n",
    "            img = cv2.imread(fp)\n",
    "            if img is not None:\n",
    "                imgs.append(img)\n",
    "\n",
    "        images_by_class.append(imgs)\n",
    "        nums.append(len(imgs))\n",
    "\n",
    "    # combine\n",
    "    all_images = []\n",
    "    for cls_imgs in images_by_class:\n",
    "        all_images.extend(cls_imgs)\n",
    "\n",
    "    # make label\n",
    "    labels = create_image_labels(nums) \n",
    "\n",
    "    return all_images, images_by_class, labels, nums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec9bcf-1d71-413a-aa30-cc62a0c14db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get pass\n",
    "\n",
    "#wire raw images\n",
    "#TrainingData\n",
    "source_dirs = [\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "]\n",
    "#TestData\n",
    "source_test_dirs = [\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "]\n",
    "\n",
    "#bright images\n",
    "#TrainingData\n",
    "target1_dirs = [\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "]\n",
    "#TestData\n",
    "test_target1_dirs = [\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "]\n",
    "\n",
    "#camera dust images\n",
    "#TrainingData\n",
    "target2_dirs = [\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "]\n",
    "#TestData\n",
    "test_target2_dirs = [\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "    r\"C:\\Users\\pass\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7180baa-04ed-45e2-bb13-e9c249695fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data and label\n",
    "source_all_imgs, source_imgs_by_class, source_label, source_num = load_7mode_images(source_dirs)\n",
    "source_test_all_imgs, source_test_imgs_by_class, source_test_label, source_test_num = load_7mode_images(source_test_dirs)\n",
    "target1_all_imgs, target1_imgs_by_class, target1_label, target1_num = load_7mode_images(target1_dirs)\n",
    "test_target1_all_imgs, test_target1_imgs_by_class, test_target1_label, test_target1_num = load_7mode_images(test_target1_dirs)\n",
    "target2_all_imgs, target2_imgs_by_class, target2_label, target2_num = load_7mode_images(target2_dirs)\n",
    "test_target2_all_imgs, test_target2_imgs_by_class, test_target2_label, test_target2_num = load_7mode_images(test_target2_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1391a9-0263-48f4-81bd-ef9549166047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization of images\n",
    "sourcefile_list = [file.astype(float)/255 for file in source_all_imgs]\n",
    "sourcefile_list = [cv2.resize(file, (360, 270)) for file in sourcefile_list]\n",
    "sourcefile_test_list = [file.astype(float)/255 for file in source_test_all_imgs]\n",
    "sourcefile_test_list = [cv2.resize(file, (360, 270)) for file in sourcefile_test_list]\n",
    "targetfile1_list = [file.astype(float)/255 for file in target1_all_imgs]\n",
    "targetfile1_list = [cv2.resize(file, (360, 270)) for file in targetfile1_list]\n",
    "test_targetfile1_list = [file.astype(float)/255 for file in test_target1_all_imgs]\n",
    "test_targetfile1_list = [cv2.resize(file, (360, 270)) for file in test_targetfile1_list]\n",
    "targetfile2_list = [file.astype(float)/255 for file in target2_all_imgs]\n",
    "targetfile2_list = [cv2.resize(file, (360, 270)) for file in targetfile2_list]\n",
    "test_targetfile2_list = [file.astype(float)/255 for file in test_target2_all_imgs]\n",
    "test_targetfile2_list = [cv2.resize(file, (360, 270)) for file in test_targetfile2_list]\n",
    "\n",
    "#numpy list\n",
    "original_source_label = source_label[\"label\"]\n",
    "original_source_label = np.array(original_source_label)\n",
    "original_source_test_label = source_test_label[\"label\"]\n",
    "original_source_test_label = np.array(original_source_test_label)\n",
    "original_target1_label = target1_label[\"label\"]\n",
    "original_target1_label = np.array(original_target1_label)\n",
    "original_test_target1_label = test_target1_label[\"label\"]\n",
    "original_test_target1_label = np.array(original_test_target1_label)\n",
    "original_target2_label = target2_label[\"label\"]\n",
    "original_target2_label = np.array(original_target2_label)\n",
    "original_test_target2_label = test_target2_label[\"label\"]\n",
    "original_test_target2_label = np.array(original_test_target2_label)\n",
    "\n",
    "\n",
    "#dummy parameter \n",
    "source_label = to_categorical(source_label[\"label\"])\n",
    "source_test_label = to_categorical(source_test_label[\"label\"])\n",
    "target1_label = to_categorical(target1_label[\"label\"])\n",
    "test_target1_label = to_categorical(test_target1_label[\"label\"])\n",
    "target2_label = to_categorical(target2_label[\"label\"])\n",
    "test_target2_label = to_categorical(test_target2_label[\"label\"])\n",
    "\n",
    "#change the data to numpy list\n",
    "#save original data\n",
    "raw_sourcefile_list = sourcefile_list\n",
    "raw_sourcefile_test_list = sourcefile_test_list\n",
    "raw_targetfile1_list = targetfile1_list\n",
    "raw_test_targetfile1_list = test_targetfile1_list\n",
    "raw_targetfile2_list = targetfile2_list\n",
    "raw_test_targetfile2_list = test_targetfile2_list\n",
    "\n",
    "#numpy list\n",
    "sourcefile_list = np.array(sourcefile_list)\n",
    "sourcefile_test_list = np.array(sourcefile_test_list)\n",
    "targetfile1_list = np.array(targetfile1_list)\n",
    "test_targetfile1_list = np.array(test_targetfile1_list)\n",
    "targetfile2_list = np.array(targetfile2_list)\n",
    "test_targetfile2_list = np.array(test_targetfile2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba6f7e-e1ed-436d-ad63-7d30e7578e1c",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dd98fb-f9b9-447f-98fc-2adfabefd92a",
   "metadata": {},
   "source": [
    "## Learning MobileNet using wire raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1c8f2-eea1-4afb-8887-6013216170f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of basemodel\n",
    "\n",
    "#read MobileNet v1\n",
    "MNet = MobileNet(include_top=False, weights=\"imagenet\",input_shape=(270,360,3))\n",
    "x = layers.Flatten()(MNet.output)\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.6)(x)\n",
    "output = layers.Dense(7, activation=\"softmax\")(x) \n",
    "\n",
    "#make basemodel\n",
    "model = keras.Model(inputs = MNet.input, outputs = output)\n",
    "\n",
    "model.trainable = True\n",
    "        \n",
    "for i in model.layers:\n",
    "    print(i.name, i.trainable)\n",
    "\n",
    "#show model network\n",
    "print(model.summary())\n",
    "\n",
    "#compile\n",
    "model.compile(optimizer=SGD(learning_rate=1e-3, momentum=0.9), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046ba9bd-b420-40ba-bdb1-f37f56d79bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=20)\n",
    "\n",
    "#execution of training\n",
    "history = model.fit(sourcefile_list, source_label, batch_size=32, epochs=100, verbose=1, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34e9b57-25a8-4360-9f33-2a6bf6826b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training curve\n",
    "\n",
    "metrics = ['loss', 'accuracy']\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "for i in range(len(metrics)):\n",
    "    metric=metrics[i]\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.title(metric)\n",
    "    \n",
    "    plt_train = history.history[metric]\n",
    "    plt_test = history.history['val_'+metric]\n",
    "    \n",
    "    plt.plot(plt_train, label='training')\n",
    "    plt.plot(plt_test, label='test')\n",
    "    plt.legend()\n",
    "    \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1059d96-e604-4eda-ae3b-9c448dfe1214",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8127d79b-3fe1-4fde-ae24-1fc044d9f7b7",
   "metadata": {},
   "source": [
    "## Evaluating the precision of MobileNet using drift images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa60377e-956a-41c8-bf92-cca4734da4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_predictions = model.predict(sourcefile_test_list)\n",
    "target1_predictions = model.predict(test_targetfile1_list)\n",
    "target2_predictions = model.predict(test_targetfile2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85797d1e-3e23-4e43-8135-683365d15da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for test raw images\n",
    "source_results = source_predictions.argmax(axis = 1)\n",
    "\n",
    "test_label = original_source_test_label\n",
    "cm = confusion_matrix(test_label, source_results)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033f34d-af8d-45fb-a10b-f153bf729cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for test bright images\n",
    "target1_results = target1_predictions.argmax(axis = 1)\n",
    "\n",
    "test_label = original_test_target1_label\n",
    "cm = confusion_matrix(test_label, target1_results)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4912927-deab-4e99-935b-bc4e072b8e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for test camera dust images\n",
    "target2_results = target2_predictions.argmax(axis = 1)\n",
    "\n",
    "test_label = original_test_target2_label\n",
    "cm = confusion_matrix(test_label, target2_results)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18d1c6d-18a3-4a91-812c-c19bec4ace21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save basemodel\n",
    "save_model(model, 'BaseModel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
