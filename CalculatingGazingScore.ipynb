{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9076294c-cbc1-4816-99f6-cd9e0777d28a",
   "metadata": {},
   "source": [
    "# Calculating Gazing Score\n",
    "## Calculate Gazing Score for choosing High Score Block in proposed model update method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc16c41-55e5-456c-be34-a37082318f85",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67c8cf-13b0-46e6-ae6e-8cfdd20bf0d9",
   "metadata": {},
   "source": [
    "## Get Score-CAM output from each block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e770e-c450-4b9e-8591-cccb31074c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import time\n",
    "from natsort import natsorted\n",
    "\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Model\n",
    "from gradcamutils import GradCam, GradCamPlusPlus, ScoreCam, GuidedBackPropagation, superimpose, read_and_preprocess_img, build_guided_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7981c5-43c3-453b-bd0a-d527cc8bf004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import images for Score-CAM\n",
    "scorefiles_0 = glob.glob(r\"C:\\Users\\pass\")\n",
    "scorefiles_1 = glob.glob(r\"C:\\Users\\pass\")\n",
    "scorefiles_2 = glob.glob(r\"C:\\Users\\pass\")\n",
    "scorefiles_3 = glob.glob(r\"C:\\Users\\pass\")\n",
    "scorefiles_4 = glob.glob(r\"C:\\Users\\pass\")\n",
    "scorefiles_5 = glob.glob(r\"C:\\Users\\pass\")\n",
    "scorefiles_6 = glob.glob(r\"C:\\Users\\pass\")\n",
    "\n",
    "#sort the files\n",
    "sorted_files_0 = natsorted(scorefiles_0)\n",
    "sorted_files_1 = natsorted(scorefiles_1)\n",
    "sorted_files_2 = natsorted(scorefiles_2)\n",
    "sorted_files_3 = natsorted(scorefiles_3)\n",
    "sorted_files_4 = natsorted(scorefiles_4)\n",
    "sorted_files_5 = natsorted(scorefiles_5)\n",
    "sorted_files_6 = natsorted(scorefiles_6)\n",
    "\n",
    "#making list\n",
    "scorefile_list = []\n",
    "\n",
    "scorefile_list0 = []\n",
    "scorefile_list1 = []\n",
    "scorefile_list2 = []\n",
    "scorefile_list3 = []\n",
    "scorefile_list4 = []\n",
    "scorefile_list5 = []\n",
    "scorefile_list6 = []\n",
    "\n",
    "for file in sorted_files_0:\n",
    "    file = cv2.imread(file)\n",
    "    scorefile_list0.append(file)\n",
    "\n",
    "for file in sorted_files_1:\n",
    "    file = cv2.imread(file)\n",
    "    scorefile_list1.append(file)\n",
    "    \n",
    "for file in sorted_files_2:\n",
    "    file = cv2.imread(file)\n",
    "    scorefile_list2.append(file)\n",
    "\n",
    "for file in sorted_files_3:\n",
    "    file = cv2.imread(file)\n",
    "    scorefile_list3.append(file)\n",
    "    \n",
    "for file in sorted_files_4:\n",
    "    file = cv2.imread(file)\n",
    "    scorefile_list4.append(file)\n",
    "\n",
    "for file in sorted_files_5:\n",
    "    file = cv2.imread(file)\n",
    "    scorefile_list5.append(file)\n",
    "\n",
    "for file in sorted_files_6:\n",
    "    file = cv2.imread(file)\n",
    "    scorefile_list6.append(file)\n",
    "\n",
    "for file in scorefile_list0:\n",
    "    scorefile_list.append(file)\n",
    "for file in scorefile_list1:\n",
    "    scorefile_list.append(file)\n",
    "for file in scorefile_list2:\n",
    "    scorefile_list.append(file)\n",
    "for file in scorefile_list3:\n",
    "    scorefile_list.append(file)\n",
    "for file in scorefile_list4:\n",
    "    scorefile_list.append(file)\n",
    "for file in scorefile_list5:\n",
    "    scorefile_list.append(file)\n",
    "for file in scorefile_list6:\n",
    "    scorefile_list.append(file)\n",
    "\n",
    "#normalization\n",
    "scorefile_list = [file.astype(float)/255 for file in scorefile_list]\n",
    "scorefile_list = [cv2.resize(file, (360, 270)) for file in scorefile_list]\n",
    "\n",
    "#numpy list\n",
    "rawscorefile_list = scorefile_list\n",
    "npscorefile_list = np.array(scorefile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe3f43-f789-4181-8aa7-75527f52d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "import gc\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "def normalize(x):\n",
    "        \"\"\"Utility function to normalize a tensor by its L2 norm\"\"\"\n",
    "        return (x + 1e-10) / (K.sqrt(K.mean(K.square(x))) + 1e-10)\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    f = np.exp(x)/np.sum(np.exp(x), axis = 1, keepdims = True)\n",
    "    return f\n",
    "\n",
    "def GradCam(model, img_array, layer_name):\n",
    "    cls = np.argmax(model.predict(img_array))\n",
    "    \n",
    "    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n",
    "    y_c = model.output[0, cls]\n",
    "    conv_output = model.get_layer(layer_name).output\n",
    "    grads = tf.gradients(y_c, conv_output)[0]\n",
    "    # grads = normalize(grads)\n",
    "\n",
    "    gradient_function = K.function([model.input], [conv_output, grads])\n",
    "    output, grads_val = gradient_function([img_array])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "\n",
    "    cam = np.dot(output, weights)\n",
    "    cam = np.maximum(cam, 0)  # Passing through ReLU\n",
    "    cam /= np.max(cam)  # scale 0 to 1.0  \n",
    "\n",
    "    return cam\n",
    "\n",
    "def GradCamPlusPlus(model, img_array, layer_name):\n",
    "    cls = np.argmax(model.predict(img_array))\n",
    "    y_c = model.output[0, cls]\n",
    "    conv_output = model.get_layer(layer_name).output\n",
    "    grads = tf.gradients(y_c, conv_output)[0]\n",
    "    # grads = normalize(grads)\n",
    "\n",
    "    first = K.exp(y_c)*grads\n",
    "    second = K.exp(y_c)*grads*grads\n",
    "    third = K.exp(y_c)*grads*grads*grads\n",
    "\n",
    "    gradient_function = K.function([model.input], [y_c,first,second,third, conv_output, grads])\n",
    "    y_c, conv_first_grad, conv_second_grad,conv_third_grad, conv_output, grads_val = gradient_function([img_array])\n",
    "    global_sum = np.sum(conv_output[0].reshape((-1,conv_first_grad[0].shape[2])), axis=0)\n",
    "\n",
    "    alpha_num = conv_second_grad[0]\n",
    "    alpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum.reshape((1,1,conv_first_grad[0].shape[2]))\n",
    "    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
    "    alphas = alpha_num/alpha_denom\n",
    "\n",
    "    weights = np.maximum(conv_first_grad[0], 0.0)\n",
    "    alpha_normalization_constant = np.sum(np.sum(alphas, axis=0),axis=0)\n",
    "    alphas /= alpha_normalization_constant.reshape((1,1,conv_first_grad[0].shape[2]))\n",
    "    deep_linearization_weights = np.sum((weights*alphas).reshape((-1,conv_first_grad[0].shape[2])),axis=0)\n",
    "\n",
    "    cam = np.sum(deep_linearization_weights*conv_output[0], axis=2)\n",
    "    cam = np.maximum(cam, 0)  # Passing through ReLU\n",
    "    cam /= np.max(cam) # scale 0 to 1.0  \n",
    "\n",
    "    return cam\n",
    "\n",
    "\n",
    "def ScoreCam(model, img_array, layer_name, max_N=-1):\n",
    "\n",
    "    cls = np.argmax(model.predict(img_array))\n",
    "    #print(cls)\n",
    "    act_map_array = Model(inputs=model.input, outputs=model.get_layer(layer_name).output).predict(img_array)\n",
    "    \n",
    "    # extract effective maps\n",
    "    if max_N != -1:\n",
    "        act_map_std_list = [np.std(act_map_array[0,:,:,k]) for k in range(act_map_array.shape[3])]\n",
    "        unsorted_max_indices = np.argpartition(-np.array(act_map_std_list), max_N)[:max_N]\n",
    "        max_N_indices = unsorted_max_indices[np.argsort(-np.array(act_map_std_list)[unsorted_max_indices])]\n",
    "        act_map_array = act_map_array[:,:,:,max_N_indices]\n",
    "\n",
    "    input_shape = model.layers[0].output_shape[0][1:]  # get input shape\n",
    "    # 1. upsampled to original input size\n",
    "    act_map_resized_list = [cv2.resize(act_map_array[0,:,:,k], input_shape[:2], interpolation=cv2.INTER_LINEAR) for k in range(act_map_array.shape[3])]\n",
    "    # 2. normalize the raw activation value in each activation map into [0, 1]\n",
    "    act_map_normalized_list = []\n",
    "    for act_map_resized in act_map_resized_list:\n",
    "        if np.max(act_map_resized) - np.min(act_map_resized) != 0:\n",
    "            act_map_normalized = act_map_resized / (np.max(act_map_resized) - np.min(act_map_resized))\n",
    "            act_map_normalized.resize(270, 360)\n",
    "        else:\n",
    "            act_map_normalized = act_map_resized\n",
    "            act_map_normalized.resize(270, 360)\n",
    "        act_map_normalized_list.append(act_map_normalized)\n",
    "    # 3. project highlighted area in the activation map to original input space by multiplying the normalized activation map\n",
    "    masked_input_list = []\n",
    "    for act_map_normalized in act_map_normalized_list:\n",
    "        masked_input = np.copy(img_array)\n",
    "        for k in range(3):\n",
    "            masked_input[0,:,:,k] *= act_map_normalized\n",
    "        masked_input_list.append(masked_input)\n",
    "    masked_input_array = np.concatenate(masked_input_list, axis=0)\n",
    "    # 4. feed masked inputs into CNN model and softmax\n",
    "    pred_from_masked_input_array = softmax(model.predict(masked_input_array))\n",
    "    # 5. define weight as the score of target class\n",
    "    weights = pred_from_masked_input_array[:,cls]\n",
    "    # 6. get final class discriminative localization map as linear weighted combination of all activation maps\n",
    "    cam = np.dot(act_map_array[0,:,:,:], weights)\n",
    "    cam = np.maximum(0, cam)  # Passing through ReLU\n",
    "    cam /= np.max(cam)  # scale 0 to 1.0\n",
    "    \n",
    "    return cam\n",
    "\n",
    "def superimpose(img_array, cam, emphasize=False):\n",
    "    \n",
    "    img_bgr = img_array\n",
    "\n",
    "    heatmap = cv2.resize(cam, (img_bgr.shape[1], img_bgr.shape[0]))\n",
    "    if emphasize:\n",
    "        heatmap = sigmoid(heatmap, 50, 0.5, 1)\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    hif = .8\n",
    "    superimposed_img = heatmap * hif + img_bgr\n",
    "    superimposed_img = np.minimum(superimposed_img, 255.0).astype(np.uint8)  # scale 0 to 255  \n",
    "    superimposed_img_rgb = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return superimposed_img_rgb\n",
    "\n",
    "import tensorflow.keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def sigmoid(x, a, b, c):\n",
    "    return c / (1 + np.exp(-a * (x-b)))\n",
    "\n",
    "\n",
    "#from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def read_and_preprocess_img(image):\n",
    "    x = image\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150df82f-a074-4c38-8a5d-7d3edf63e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('BaseModel.h5')\n",
    "\n",
    "for i in range(len(scorefile_list)):\n",
    "    index = i\n",
    "    raw_image = rawscorefile_list[index]\n",
    "    image = scorefile_list[index]\n",
    "    img_array = read_and_preprocess_img(image)\n",
    "    layer_name = \"conv_pw_1_relu\"\n",
    "    score_cam=ScoreCam(model,img_array,layer_name)\n",
    "    scorecam_rescaled = cv2.resize(score_cam, (360, 270))\n",
    "    scorecam_rescaled = (scorecam_rescaled * 255).astype(np.uint8)  \n",
    "    cv2.imwrite('saved_image' + str(index) + '.jpg', scorecam_rescaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca89cae-c236-4e9e-9351-665c83357e98",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d2215b-a0d3-420a-a0b6-7c2503622eb0",
   "metadata": {},
   "source": [
    "## Calculate Gazing Score using Score-CAM result got above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02beae17-b54e-42d0-bae0-62fecc7a024a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import re\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cdbbc8-9b0f-4b2f-a6f5-d712300b1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get processed images(these images are processed to mask images)\n",
    "files_0 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_1 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_2 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_3 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_4 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_5 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_6 = glob.glob(r\"C:\\Users\\pass\")\n",
    "\n",
    "#sort\n",
    "sorted_files_0 = natsorted(files_0)\n",
    "sorted_files_1 = natsorted(files_1)\n",
    "sorted_files_2 = natsorted(files_2)\n",
    "sorted_files_3 = natsorted(files_3)\n",
    "sorted_files_4 = natsorted(files_4)\n",
    "sorted_files_5 = natsorted(files_5)\n",
    "sorted_files_6 = natsorted(files_6)\n",
    "\n",
    "file_list = []\n",
    "\n",
    "file_list0 = []\n",
    "file_list1 = []\n",
    "file_list2 = []\n",
    "file_list3 = []\n",
    "file_list4 = []\n",
    "file_list5 = []\n",
    "file_list6 = []\n",
    "\n",
    "for file in sorted_files_0:\n",
    "    file = cv2.imread(file)\n",
    "    file_list0.append(file)\n",
    "\n",
    "for file in sorted_files_1:\n",
    "    file = cv2.imread(file)\n",
    "    file_list1.append(file)\n",
    "    \n",
    "for file in sorted_files_2:\n",
    "    file = cv2.imread(file)\n",
    "    file_list2.append(file)\n",
    "\n",
    "for file in sorted_files_3:\n",
    "    file = cv2.imread(file)\n",
    "    file_list3.append(file)\n",
    "    \n",
    "for file in sorted_files_4:\n",
    "    file = cv2.imread(file)\n",
    "    file_list4.append(file)\n",
    "\n",
    "for file in sorted_files_5:\n",
    "    file = cv2.imread(file)\n",
    "    file_list5.append(file)\n",
    "\n",
    "for file in sorted_files_6:\n",
    "    file = cv2.imread(file)\n",
    "    file_list6.append(file)\n",
    "\n",
    "for file in file_list0:\n",
    "    file_list.append(file)\n",
    "for file in file_list1:\n",
    "    file_list.append(file)\n",
    "for file in file_list2:\n",
    "    file_list.append(file)\n",
    "for file in file_list3:\n",
    "    file_list.append(file)\n",
    "for file in file_list4:\n",
    "    file_list.append(file)\n",
    "for file in file_list5:\n",
    "    file_list.append(file)\n",
    "for file in file_list6:\n",
    "    file_list.append(file)\n",
    "    \n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4876eb7-c45d-48c7-8d9e-89b536d4e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of color range of red\n",
    "\n",
    "lower_red1 = np.array([0, 50, 50])   \n",
    "upper_red1 = np.array([10, 255, 255]) \n",
    "lower_red2 = np.array([170, 50, 50])  \n",
    "upper_red2 = np.array([180, 255, 255]) \n",
    "\n",
    "right_score = 1.0\n",
    "fault_score = -0.1\n",
    "\n",
    "#list for mask images\n",
    "mask_list = []\n",
    "\n",
    "#make mask images\n",
    "for img in file_list:\n",
    "\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    mask1 = cv2.inRange(hsv_img, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv_img, lower_red2, upper_red2)\n",
    "    mask = cv2.bitwise_or(mask1, mask2)  \n",
    "\n",
    "    processed_img = np.full(img.shape[:2], fault_score)  \n",
    "    processed_img[mask > 0] = right_score  \n",
    "    mask_list.append(processed_img)\n",
    "\n",
    "mask_list = [cv2.resize(file, (360, 270)) for file in mask_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb394006-c841-4785-ac64-5a9dd6b03f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import score-cam result\n",
    "files_block1 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_block2 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_block3 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_block4 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_block5 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_block6 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_block7 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_block8 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_block9 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_block10 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_block11 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_block12 = glob.glob(r\"C:\\Users\\pass\")\n",
    "files_block13 = glob.glob(r\"C:\\Users\\pass\")\n",
    "\n",
    "\n",
    "# sort\n",
    "sorted_block1 = natsorted(files_block1)\n",
    "sorted_block2 = natsorted(files_block2)\n",
    "sorted_block3 = natsorted(files_block3)\n",
    "sorted_block4 = natsorted(files_block4)\n",
    "sorted_block5 = natsorted(files_block5)\n",
    "sorted_block6 = natsorted(files_block6)\n",
    "sorted_block7 = natsorted(files_block7)\n",
    "sorted_block8 = natsorted(files_block8)\n",
    "sorted_block9 = natsorted(files_block9)\n",
    "sorted_block10 = natsorted(files_block10)\n",
    "sorted_block11 = natsorted(files_block11)\n",
    "sorted_block12 = natsorted(files_block12)\n",
    "sorted_block13 = natsorted(files_block13)\n",
    "\n",
    "file_list_block1 = []\n",
    "file_list_block2 = []\n",
    "file_list_block3 = []\n",
    "file_list_block4 = []\n",
    "file_list_block5 = []\n",
    "file_list_block6 = []\n",
    "file_list_block7 = []\n",
    "file_list_block8 = []\n",
    "file_list_block9 = []\n",
    "file_list_block10 = []\n",
    "file_list_block11 = []\n",
    "file_list_block12 = []\n",
    "file_list_block13 = []\n",
    "\n",
    "\n",
    "for file in sorted_block1:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block1.append(file)\n",
    "\n",
    "for file in sorted_block2:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block2.append(file)\n",
    "    \n",
    "for file in sorted_block3:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block3.append(file)\n",
    "\n",
    "for file in sorted_block4:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block4.append(file)\n",
    "    \n",
    "for file in sorted_block5:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block5.append(file)\n",
    "\n",
    "for file in sorted_block6:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block6.append(file)\n",
    "\n",
    "for file in sorted_block7:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block7.append(file)\n",
    "\n",
    "for file in sorted_block8:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block8.append(file)\n",
    "\n",
    "for file in sorted_block9:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block9.append(file)\n",
    "    \n",
    "for file in sorted_block10:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block10.append(file)\n",
    "\n",
    "for file in sorted_block11:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block11.append(file)\n",
    "    \n",
    "for file in sorted_block12:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block12.append(file)\n",
    "\n",
    "for file in sorted_block13:\n",
    "    file = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    file_list_block13.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b17b00-b304-4de5-9da3-cce18cff2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuctions for calculating Gazing Score from mask image and score-cam result\n",
    "def combine_images(mask_image, grayscale_image, right_score, fault_score):\n",
    "    mask_ones = mask_image == right_score\n",
    "    mask_negative_ones = mask_image == fault_score\n",
    "    \n",
    "    combined_ones = mask_ones * grayscale_image\n",
    "    combined_negative_ones = mask_negative_ones * grayscale_image * fault_score\n",
    "    \n",
    "    sum_ones = np.sum(combined_ones)\n",
    "    sum_negative_ones = np.sum(combined_negative_ones)\n",
    "    \n",
    "    count_ones = np.sum(mask_ones)\n",
    "    count_negative_ones = np.sum(mask_negative_ones)\n",
    "    \n",
    "    avg_ones = sum_ones / count_ones if count_ones > 0 else 0\n",
    "    avg_negative_ones = sum_negative_ones / count_negative_ones if count_negative_ones > 0 else 0\n",
    "    \n",
    "    return avg_ones + avg_negative_ones\n",
    "\n",
    "def process_multiple_images(mask_list, file_list_block):\n",
    "    results = []\n",
    "    \n",
    "    if len(mask_list) != len(file_list_block):\n",
    "        raise ValueError(\"the lengths of mask_list and file_list_block are different\")\n",
    "    \n",
    "    for i in range(len(mask_list)):\n",
    "        mask_image = mask_list[i]\n",
    "        grayscale_image = file_list_block[i]\n",
    "        \n",
    "        result = combine_images(mask_image, grayscale_image, right_score, fault_score)\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf5929-9e2d-4961-a5b3-b124dbb32f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate Gazing Score for each block\n",
    "result_block1 = process_multiple_images(mask_list, file_list_block1)\n",
    "result_block2 = process_multiple_images(mask_list, file_list_block2)\n",
    "result_block3 = process_multiple_images(mask_list, file_list_block3)\n",
    "result_block4 = process_multiple_images(mask_list, file_list_block4)\n",
    "result_block5 = process_multiple_images(mask_list, file_list_block5)\n",
    "result_block6 = process_multiple_images(mask_list, file_list_block6)\n",
    "result_block7 = process_multiple_images(mask_list, file_list_block7)\n",
    "result_block8 = process_multiple_images(mask_list, file_list_block8)\n",
    "result_block9 = process_multiple_images(mask_list, file_list_block9)\n",
    "result_block10 = process_multiple_images(mask_list, file_list_block10)\n",
    "result_block11 = process_multiple_images(mask_list, file_list_block11)\n",
    "result_block12 = process_multiple_images(mask_list, file_list_block12)\n",
    "result_block13 = process_multiple_images(mask_list, file_list_block13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c29e24-0b88-4928-8a73-a7e19dba63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data = [result_block1, result_block2, result_block3, result_block4, result_block5, result_block6, result_block7, result_block8, result_block9, result_block10, result_block11, result_block12, result_block13]\n",
    "\n",
    "# CSV output\n",
    "def save_to_csv(data, filename=\"whichlayer.csv\"):\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# save\n",
    "save_to_csv(data, \"whichlayer.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
